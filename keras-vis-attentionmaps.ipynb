{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from vis.utils import utils\n",
    "from vis.utils.vggnet import VGG16\n",
    "from vis.visualization import visualize_saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:73: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"block1_conv1\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(img_input)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:74: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"block1_conv2\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block2_conv1\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block2_conv2\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:83: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"block3_conv1\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:84: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"block3_conv2\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"block3_conv3\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block4_conv1\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block4_conv2\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:91: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block4_conv3\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:95: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block5_conv1\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block5_conv2\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2')(x)\n",
      "/usr/local/lib/python3.5/dist-packages/vis/utils/vggnet.py:97: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block5_conv3\", padding=\"same\", activation=\"relu\")`\n",
      "  x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    }
   ],
   "source": [
    "# Build the VGG16 network with ImageNet weights\n",
    "model = VGG16(weights='imagenet', include_top=True)\n",
    "print('Model loaded.')\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# (see model definition in vggnet.py)\n",
    "layer_name = 'predictions'\n",
    "layer_idx = [idx for idx, layer in enumerate(model.layers) if layer.name == layer_name][0]\n",
    "\n",
    "# Images corresponding to tiger, penguin, dumbbell, speedboat, spider\n",
    "image_paths = [\n",
    "    \"http://www.tigerfdn.com/wp-content/uploads/2016/05/How-Much-Does-A-Tiger-Weigh.jpg\",\n",
    "    \"http://www.slate.com/content/dam/slate/articles/health_and_science/wild_things/2013/10/131025_WILD_AdeliePenguin.jpg.CROP.promo-mediumlarge.jpg\",\n",
    "    \"https://www.kshs.org/cool2/graphics/dumbbell1lg.jpg\",\n",
    "    \"http://tampaspeedboatadventures.com/wp-content/uploads/2010/10/DSC07011.jpg\",\n",
    "    \"http://ichef-1.bbci.co.uk/news/660/cpsprodpb/1C24/production/_85540270_85540265.jpg\"\n",
    "]\n",
    "\n",
    "heatmaps = []\n",
    "for path in image_paths:\n",
    "    # Predict the corresponding class for use in `visualize_saliency`.\n",
    "    seed_img = utils.load_img(path, target_size=(224, 224))\n",
    "    pred_class = np.argmax(model.predict(np.array([img_to_array(seed_img)])))\n",
    "\n",
    "    # Here we are asking it to show attention such that prob of `pred_class` is maximized.\n",
    "    heatmap = visualize_saliency(model, layer_idx, [pred_class], seed_img, text=utils.get_imagenet_label(pred_class))\n",
    "    heatmaps.append(heatmap)\n",
    "\n",
    "cv2.imshow(\"Saliency map\", utils.stitch_images(heatmaps))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
